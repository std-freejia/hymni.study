# 컴구__메모리

### 개요

![Figure 1](https://github.com/Sundislikesun/Sun-crazy-world/blob/main/Computer%20System/image-20201118161339109.png)


##### 분류

1. 저장 매체로 구분
   
   - 반도체 메모리 : 휘발성, 정전 후 정보 손실, 대규모 집적 회로
     
     - 바이폴라 (TTL) 반도체 메모리 : 고속
     
     - MOS 반도체 메모리 : 고집적이므로 더 많이 사용
     
   - 자기 표면 메모리 : 비 휘발성
     
     - 카세트테이프
     
     - 디스크
     
     - 마그네틱 드럼 (현대 컴퓨터에서는 거의 사용되지 않음)
     
   - 자기 코어 메모리 : 비 휘발성 (최신 컴퓨터에서는 거의 사용되지 않음)
   
   - CD 메모리 : 비 휘발성
   
2. 액세스 방법으로 구분

   - 랜덤 액세스 메모리 (RAM, Random Access Memory) : 물리적 위치 순서대로 주소를 지정할 필요가 없음
     
     - 정적 RAM (Static RAM) : 트리거 원리, 캐시는 대부분 정적 RAM을 사용
     
     - 동적 RAM (Dynamic RAM) : 커패시터 충전 및 방전 원리는 새로 고침이 필요하며 대부분의 주 메모리는 동적 RAM을 사용
     
   - 읽기 전용 메모리 (ROM, Read Only Memory) : 물리적 위치 순서대로 주소를 지정할 필요가 없음. 고정 된 정보를 저장하고 운영 체제를 치료하는 데 사용
     
     - 마스크 형 읽기 전용 메모리 (MROM, Masked ROM)
     
     - 프로그래밍 가능 읽기 전용 메모리 (PROM, Programmable ROM) : 일회성 프로그래밍 가능
     
     - 프로그래밍 가능 삭제 가능 읽기 전용 메모리 (EPROM, Erasable Programmable ROM) : 지우는 방법은 자외선으로 조사하거나 전기적으로 지울 수 있음, 즉, EEPROM
     
     - 전기적으로 소거 가능한 프로그래밍 가능 ROM (EEPROM, Electrically Erasable Programmable ROM)
     
     - 플래시 메모리 (Flash Memory) : EEPROM의 특성을 가지고 있지만 훨씬 빠르고 RAM의 기능을 가지고 있음. CPU에 직접 연결할 수 있으며 디스크를 대체 할 수도 있음.
     
   - 직렬 액세스 메모리 : 물리적 위치 순서로 주소 지정
     
     - 순차 액세스 메모리 : 매체의 시작부터 순차적으로 주소 지정해야 함, 예: 테이프.
     
     - 직접 액세스 메모리 : 먼저 특정 영역에 직접 액세스 한 다음 순차적으로 주소 지정, 예: 디스크.

3. 기능별로 구분

   - 메인 메모리 : CPU와 직접 정보 교환

   - 캐시 : 구성 요소 속도 불일치 문제 해결

   - 보조 메모리 : CPU와 직접 정보를 교환 할 수 없으며 스토리지 용량 문제를 해결하는 데 사용



##### 메모리 계층

​	![Figure](https://github.com/Sundislikesun/Sun-crazy-world/blob/main/Computer%20System/image-20201118171308896.png)

​			위에서 아래로 : 속도 느려짐, 용량 증가, 가격 떠러짐




1. 캐시 - 메인 메모리

   - CPU 및 메인 메모리 속도 불일치 문제 해결

   - 캐시는 CPU와 직접 정보를 교환하거나 메인 메모리와 직접 정보를 교환 할 수 있음.

2. 메인 메모리 - 보조 메모리

   - 스토리지 용량 문제 해결

   - 보조 메모리는 CPU와 직접 정보를 교환 할 수 없으며 메인 메모리와 만 정보를 교환

   - 가상 메모리 시스템



------

### 메인 메모리

##### CPU와 연결

1. 저장 용량 확장

   여러 메모리 칩을 함께 연결

   - 비트 확장 : 저장 단어 길이를 확장. 예를 들어 2 개의 1K x 4 비트 칩이 1K x 8 비트 메모리를 형성 할 수 있음. 즉, <u>데이터 라인 수를 확장</u>.

   - 단어 확장 : 저장 단어 수를 확장. 예를 들어 2 개의 1K x 8 비트 칩은 2K x 8 비트 메모리를 형성 할 수 있음. 즉, <u>주소 라인 수를 확장</u>. 이 경우는 칩 선택 신호가 필요.

   - 단어 및 비트 확장 : 비트 확장 + 단어 확장

2. CPU와 연결

   - 주소 라인 연결 : CPU 주소 라인의 하위 비트는 메모리 주소 라인에 연결되고 CPU 주소의 상위 비트는 칩 선택 신호 생성과 같은 다른 용도로 사용.

   - 데이터 라인 연결 : 메모리 칩은 CPU 데이터 라인 수와 같은 데이터 라인 수를 만들기 위해 비트 확장되어야 함.

   - 읽기 및 쓰기 명령 라인 연결 

   - 칩 선택 라인 연결

   - 메모리 칩 선택 : RAM or ROM,  일반적으로 ROM은 시스템 프로그램, 표준 서브 루틴, 상수 등을 저장하는 데 사용되며 RAM은 사용자 프로그램에 사용.

   예 : CPU에 16 개의 주소 라인과 8 개의 데이터 라인이 있고 메모리 액세스 제어 신호 (액티브 로우)로 MREQ를 사용하고 읽기 / 쓰기 제어 신호로 WR (하이 레벨은 읽기, 로우 레벨은 쓰기)을 사용한다고 가정합니다. 다음 메모리 칩을 사용할 수 있습니다 : 1K x 4 비트 RAM, 4K x 8 비트 RAM, 8K x 8 비트 RAM, 2K x 8 비트 ROM, 4K x 8 비트 ROM, 8K x 8 비트 ROM 및 74138 변환 코더 및 다양한 게이트 회로. CPU와 메모리 간의 연결 다이어그램을 그리면 요구 사항은 다음과 같습니다.

   1. 메인 메모리 주소 공간 할당 :

       6000H ~ 67FFH는 시스템 프로그램 영역입니다.

       6800H ~ 6BFFH는 사용자 프로그램 영역입니다.

   2. 메모리 칩을 합리적으로 선택하고 각각에서 선택할 칩 수를 설명하십시오.

   3. 메모리 칩의 칩 선택 로직 다이어그램을 자세히 그립니다.

![Figure](https://github.com/Sundislikesun/Sun-crazy-world/blob/main/Computer%20System/image-20201123145146042.png)



##### 메모리 액세스 속도 향상

1. 메모리 액세스 속도를 향상시키는 방법 :

   - 고속 부품 사용

   - 캐시-메인 메모리 계층 채택

   - 메인 메모리 구조 조정

2. 메인 메모리 구조 조정

   - 단일 뱅크 멀티 워드 시스템 : 메모리 뱅크에는 여러 개의 워드가 포함되어 있으며 각 워드는 하나의 명령어 또는 데이터를 저장하므로 한 번의 저장주기에서 여러 명령어 또는 데이터를 가져올 수 있음.

   - 멀티 뱅크 병행 시스템 : 여러 메모리 뱅크를 사용하여 병행으로 작업 수행.

     - 상위 교차 주소 지정 : 순차 저장이라고도 함. 즉, 한 뱅크가 가득 차서 다른 뱅크에 저장. 상위 주소는 뱅크 번호를 저장하고 하위 주소는 뱅크 내부 주소 저장.

     - 하위 교차 주소 지정 : 교차 저장이라고도 함. 즉, 인접한 뱅크에 순서대로 저장. 하위 주소는 뱅크 번호를 저장하고 상위 주소는 내부 주소 저장.

     ！하위 교차 주소 지정은 상위 교차 주소 지정보다 연속적으로 n 개 단어를 읽는 데 더 적은 시간 필요.

3. 고성능 메모리 칩 사용

   - SDRAM (Synchronous DRAM) : CPU와의 데이터 교환은 시스템의 클록 신호와 동기화되며, CPU는 메모리의 내부 작동이 완료 될 때까지 기다릴 필요가 없음. 버스트 액세스 모드를 지원하고 CPU는 주소 하나를 통해 데이터 블록에 지속적으로 액세스 가능. 또한 여러 메모리 뱅크를 포함 할 수 있음.

   - DDR-SDRAM (Double Data Rate SDRAM) : 주기 당 CPU에게 두 번 데이터를 전송하는 SDRAM의 향상된 버전

   - RDRAM (Rambus DRAM) : 주로 메모리 대역폭 문제를 해결.

   - CDRAM (DRAM with Cache) : EDRAM (Enhanced DRAM)이라고도함. 일반적인 DRAM 칩에 작은 SRAM을 통합.



##### 메모리 검증

해밍 코드 : 1 비트 오류 수정, k 비트 감지 비트가 n 비트 이진 코드에 삽입.



------

### 캐시

##### 개요

1. 캐시를 사용하는 이유

   - I / O 장치는 CPU보다 더 높은 수위로 메인 메모리를 요청할 수 있으모로 CPU는 I / O 장치가 메모리 방문 끝날때까지 기다려야 해서 CPU 효율성이 감소.

   - 메인 메모리 속도는 CPU 속도보다 훨씬 느림.

2. 캐시 작동 방식

   - 명령과 데이터는 메인 메모리에 지속적으로 저장되므로 CPU가 프로그램을 실행할 때 메모리 액세스는 로컬.

   - CPU가 곧 사용할 프로그램과 데이터를 캐시에 미리 저장하여 CPU가 일정 시간 동안 캐시만 액세스 하면 됨.

   - 메인 메모리 주소와 캐시 주소 간의 매핑을 구현하기 위해 메인 메모리와 캐시는 모두 여러 블록으로 나뉘며 각 블록에는 여러 단어가 포함

   - CPU와 캐시는 일반적으로 한 번에 한 단어를 전송하고 캐시와 주 메모리는 한 번에 한 블록을 전송

3. 캐시의 기본 구조

   - 캐시 메모리 : 일반적으로 고속 SRAM으로 구성되며, 메모리 액세스 우선 순위가 가장 높고 블록 단위로  메인 메모리와 정보를 교환.

   - 주소 매핑 변환 메커니즘 : 메인 메모리 주소에서 캐시 주소로 변환; 명중되면 CPU가 캐시에 직접 액세스 할 수 있고, 명중 안 된 경우 CPU는 메인 메모리에 액세스하고, 단어를 포함하는 단어 블록을 캐시로 전송

   - 교체 메커니즘 : 블록이 캐시에로드 될 때 캐시가 가득 차면 캐시의 이전 블록을 새 블록으로 교체

   - 캐시 읽기 및 쓰기 작업 :

     - 읽기 작업 : 명중 여부를 판단하고 명중되면 CPU가 캐시 메모리에 직접 액세스 할 수 있고, 명중 안 된경우 CPU가 메인 메모리에 액세스하고, 단어를 꺼내어 캐시로 단어 블록을 전송하고, 캐시가 가득 차면 블록 교체.

     - 쓰기 작업 : 캐시와 메인 메모리를 일관되게 만드는 방법

       1. Write-through : Store-through 라고도하며 쓰기 작업이 수행할 때 캐시와 메인 메모리에 모두 저장.

       2. Write-back 방법 : copy-back 이라고도하며 쓰기 작업을 수행할 때는 캐시에만 쓰고 캐시가 교체되면 메인 메모리에 저장.

4. 캐시 개선

   - single cache 및 second level cache

     - single cache : 온칩 캐시라고도하며 CPU와 메인 메모리 사이에 캐시가 하나만 있으며 일반적으로 CPU 칩에 통합되어 있음. 오프 칩 버스가 필요하지 않으며 액세스 속도가 빠르지만 용량이 적고 명중률이 높지 않음.

     - second level cache : 오프 칩 캐시라고도하며 메인 메모리와 온칩 캐시 사이에 하나의 캐시를 추가.

   - 통합 캐시 및 별도 캐시 : 메인 메모리 구조 및 명령 실행 제어 방법 관련

     - 통합 캐시 : 명령과 데이터가 동일한 캐시에 저장

     - 별도 캐시 : 명령어와 데이터는 서로 다른 캐시, 즉 명령어 캐시 + 데이터 캐시에 저장



##### 캐시-메인 메모리 주소 매핑

1. 직접 매핑 : 각 메인 메모리 블록은 하나의 캐시 블록에만 해당

   메인 메모리 주소 = 메인 메모리 블록 태그 + 캐시 블록 주소 + 블록 내 주소

2. 완전 연관 매핑 : 각 메인 메모리 블록은 모든 캐시 블록에 대응

   메인 메모리 주소 = 메인 메모리 블록 태그 + 블록 내 주소

3. 그룹 연관 매핑 : 캐시 블록을 그룹으로 나누고, 각 메인 메모리 블록은 특정 그룹의 모든 캐시 블록에 대응.

   메인 메모리 주소 = 메인 메모리 블록 태그 + 그룹 주소 + 블록 내 주소



##### 캐시 교체 방식

1. 선입 선출 (FIFO, First-In-First-Out)

2. 최소 최근 사용 (LAU, Least Recently Used)

3. 무작위 교체 방법



------

### Memory Management

##### Overview

1. Memory management methods

   - Monoprogramming : only one process exists in the memory.
   - Multiprogramming (fixed partition) : segment the memory to several fixed partitions, one partition for one process.
   - Swapping : swap the idle process to hard disk and load it when necessary.
   - Virtual memory : split program into several pieces, called overlays; load overlays when it is needed and swap the inactive overlays; logical address space can be bigger than physical address space.

2. Comparison

   |                       |  **Mono**   |     **MFP**      |        **Swapping**         |
   | :-------------------: | :---------: | :--------------: | :-------------------------: |
   |  **Size of process**  | < Total mem | < Partition size | < Total size of Free memory |
   |    **Allocation**     |   Static    |      Static      |           Dynamic           |
   | **Multi-programming** | Unsupported |    Supported     |          Supported          |
   |   **Memory space**    | Continuous  |    Continuous    |         Continuous          |
   |   **Memory growth**   | Unsupported |   Unsupported    |          Supported          |

##### Swapping

1. Memory management techniques

   - Use <u>Bitmap</u> : describe the memory as a memory block array; use a bitmap to record the status of blocks, ‘0’ means free while ‘1’ means occupied.
     - Allocation: Find continuous ‘0’ bits in the bitmap.
     - Retraction: set the corresponding bits to be ‘0’.

   - Use <u>Dynamic List</u> : use a dynamic list to record the status of blocks, ‘Hole segment’ means free while  ‘Proc segment’ means occupied.

     - Allocation: search in the list and find a proper segment; if the segment size is bigger than required size, divide the segment.
     - Retraction: change the type of segment and update the list.
     - Segment allocation methods : 외부 단편화를 없애는 연속 메모리 할당 방식
       1. First-fit : search from the head and allocate the first suitable segment.
       2. Next-fit : search from the last allocated segment and and allocate the first suitable segment.
       3. Best-fit : arrange the list in ascending order and allocate the smallest suitable segment.
       4. Worst-fit : arrange the list in descending order and allocate the biggest suitable segment.
       5. Quick-fit : maintain a separate list for segments of commonly used size.

2. Disadvantage

   - Too many fragments, but can be eliminated by ‘compaction’ operation.
   - Resource-consuming

##### Virtual memory

- <u>Size of process can be bigger than total memory size.</u>

- <u>프로세스의 모든 코드는 항상 필요한 것이 아니라서 필요한 부분만 메모리에 올림.</u>

1. Paging : 내부 단편화가 발생할 수 있다.

   - Page : unit to describe the logical space of process.

     Frame : unit to describe the physics space of memory.

     Size of Page = Size of Frame

     Page Table : mapping between page and frame; 메모리에 저장.

     <!--PTBR(Page-Table Base Register)가 page table을 가리키고, PTLR(Page-Table Length Register)가 page table의 크기를 가지고 있다.-->

   - Address mapping : translate logical address to physical address; get done in MMU (Memory Management Unit).

     Memory allocation : Global page table + Local page table

     Scheduling : load pages from disk; adjacent pages can be stored in discontinuous frames.

     Page replacement : swap inactive pages to disk.

   - Page table structure

     - Multi-level page table(Hierarchical Paging)

       ​	<u>Improve index speed;</u>

       ​	<u>모든 페이지를 로드할 필요 없다.</u>

     - Hashed Page Tables

       ​	<u>Hash table을 이용해 page table을 관리;</u>

       ​	<u>Address space가 32bit보다 커지면 hierarchical paging 비효율적이기 때문에 주로 이 방법 사용;</u>

       ​	<u>매우 빠르지만 구현이 어렵다.</u>

     - Inverted page table

       ​	<u>Translate physical address to logical address.</u>

       ​	<u>메모리를 훨씬 적게 사용, 시간이 오래 걸린다;</u>

       ​	<u>대부분의 메모리는 inverted page table과 hashed page table을 결합하는 방식으로 구현.</u>

     - TLB(Translation Look-aside Buffer) : Hard device for address mapping directly; a “cache” for page table.

       ​	<u>key-value pair로 데이터를 관리;</u>

       ​	<u>CPU는 page table보다 TLB을 우선적으로 참조.</u>

     - Software TLB : TLB + OS operation

   - Memory protection : page table의 각 항목에는 valid-invalid bit가 붙어있어 그 값이 valid라면 해당 페이지에 접근이 가능하고, invalid라면 해당 페이지가 메모리에 없어 접근할 수 없다.

   - Shared Pages : reentrant code(또는 pure code)가 공유 가능. reentrant code는 runtime 동안 절대로 변하지 않는 코드이며, 따라서 여러 프로세스들이 동시에 같은 코드를 수행할 수 있다.

   - Page Fault

     - The page is not existed in the memory.

     - An empty frame is need to store the page.

     - Demand Paging : 요구되는 페이지만 메모리에 올린다.

       1. Pure demand paging : 페이지를 요구할 때만 메모리에 적재.

          <u>메모리의 낭비 매우 줄일 수 있다;</u>

           <u>속도 느리다.</u>

       2. Prepaging : 우선 필요할 것 같은 페이지를 적재.

          <u>메모리 낭비될 수 있다;</u>

          <u>속도 빠르다.</u>

   - Page Replacement

     - All frames are occupied when page fault occurs.

     - Select a frame and replace with the new page.

     - Replacement method

       1. Global replacement : 메모리 상의 모든 프로세스 페이지에 대해 교체.
       
       2. Local replacement : 메모리 상의 자기 프로세스 페이지에서만 교체.

       ! 실제로 전체를 기준으로 페이지를 교체하는 것이 더 효율적이라고 할 수 있다.

   - Algorithms

     1. FIFO : replace the oldest page.

     2. OPT(Optimal) : 앞으로 가장 사용하지 않을 페이지를 가장 우선적으로 내려 보낸다.

     3. Second chance : replace the not-referenced and oldest page.

     4. Clock : using a circular list in second chance algorithm.

     5. NRU() : replace the pages with the least class number.

        ​		Class 0 (00): not referenced and not modified

        ​		Class 1 (01): not referenced but modified

        ​		Class 2 (10): referenced but not modified

        ​		Class 3 (11): referenced and modified

     6. LRU(Least-Recently-Used) : 최근에 사용하지 않은 페이지를 가장 먼저 내려 보낸다.

     7. NFU(aging algorithm) : 

     8. Working set : prepaging based on working set.

          ​		Working set W(k,t) : pages used during last K memory reference or in last t seconds.

     - Comparison

       |                  |     **Principle**     |        **Performance**        |
       | :--------------: | :-------------------: | :---------------------------: |
       | **Most optimal** | Running flow is known | Perfect but can’t be realized |
       |     **NRU**      |  “RM” classification  |    Not bad, time-consuming    |
       |     **FIFO**     |     Time sorting      |        Not reasonable         |
       |  **LRU & NFU**   |    Locally optimal    |      Approach “perfect”       |
       | **Working set**  |       Prepaging       |     Stable and efficiency     |

2. Segmentation

   - Segment : logical partition of program, such as code segment, data segment, stack segment, etc; size of segment is not fixed.

   - Address mapping : addr of segment + offset in segment

     Memory allocation : Global segment table + Local segment table

     Scheduling : load segment when needed.

   - 보호와 공유의 기능을 수행하기 쉬워지는 것이다.

   - Mechanism of TLB

   - Pure segmentation

     - May generate external fragment.
     - External fragment can be eliminated by ‘compaction’ operation.

   - Segment + paging

     - 세그먼테이션은 보호와 공유 면에서 효과적이고 페이징은 외부 단편화 문제 해결에 효과적이다.
     - 속도 면에서 조금 떨어질 수 있다.
     - Use segment technique to organize the content of program, and use paging technique to organize the physical memory.
     - 각 세그먼트를 일정 간격인 페이지 단위로 자른다.

![img](https://t1.daumcdn.net/cfile/tistory/22255E42590C1D9607)
